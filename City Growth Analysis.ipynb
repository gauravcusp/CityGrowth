{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The idea of this project is to identify economic determinants of urban growth that could help economists get better insights about cities across the world. \n",
    "\n",
    "### Since the change in urban landscape correlates highly with increase in income, reduced travel time and better ammenities, we'll be using some of these variables to assess what causes urban growth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "import urllib\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from shapely.geometry import Point, Polygon, MultiPoint\n",
    "from shapely import wkt\n",
    "import shapely.speedups\n",
    "from shapely.ops import transform, nearest_points\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import gdal\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import glob\n",
    "from functools import partial\n",
    "import pyproj\n",
    "import osmnx as ox\n",
    "from IPython.display import Image\n",
    "import make_fishnet\n",
    "import cbd_osm\n",
    "import geocoder\n",
    "from pandana.loaders import osm\n",
    "import pandana\n",
    "import pylab as pl\n",
    "ox.config(log_console=True, use_cache=True)\n",
    "pl.rcParams[\"figure.figsize\"] = (10,10)\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll be using a lot of geographic data for this analysis, so its important to transform data to local projections in order to get accurate results. The function below searches the EPSG API for a local projection and transforms the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_proj_crs(to_crs):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to indentify local projection for cities dynamically\n",
    "    \n",
    "    Input:\n",
    "    to_crs : name of city / country; epsg if known\n",
    "    \n",
    "    Returns:\n",
    "    Local epsg (in string)\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(to_crs, int):\n",
    "        to_crs = to_crs\n",
    "    elif isinstance(to_crs, str):\n",
    "        city, country = to_crs.split(',')\n",
    "        url = \"http://epsg.io/?q={}&format=json&trans=1&callback=jsonpFunction\".format(city)\n",
    "        r = requests.get(url)\n",
    "        if r.status_code == 200:\n",
    "            js = json.loads(r.text[14:-1])\n",
    "            \n",
    "            if js['number_result'] != 0:\n",
    "                lis = []\n",
    "                for i in js['results']:\n",
    "                    res = i\n",
    "                    if (res['unit'] == 'metre') and (res['accuracy'] == 1.0):\n",
    "                        lis.append(res['code'])\n",
    "                if len(lis) == 0:\n",
    "                    for i in js['results']:\n",
    "                        res = i\n",
    "                        if res['unit'] == 'metre':\n",
    "                            lis.append(res['code'])\n",
    "                    return lis[0]\n",
    "                else:\n",
    "                    return lis[0]\n",
    "   \n",
    "            else:\n",
    "                url = \"http://epsg.io/?q={}&format=json&trans=1&callback=jsonpFunction\".format(country)\n",
    "                r = requests.get(url)\n",
    "                if r.status_code == 200:\n",
    "                    js = json.loads(r.text[14:-1])\n",
    "\n",
    "                    if js['number_result'] != 0:\n",
    "                        lis = []\n",
    "                        for i in js['results']:\n",
    "                            res = i\n",
    "                            if (res['unit'] == 'metre') and (res['accuracy'] == 1.0):\n",
    "                                lis.append(res['code'])\n",
    "                        if len(lis) == 0:\n",
    "                            for i in js['results']:\n",
    "                                res = i\n",
    "                                if res['unit'] == 'metre':\n",
    "                                    lis.append(res['code'])\n",
    "                            return lis[0]\n",
    "                        else:\n",
    "                            return lis[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3788'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Testing the function for Auckland, New Zealand\n",
    "\n",
    "get_city_proj_crs('Auckland, New Zealand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll also need a function to repeoject geometry objects like point and polygons. So we'll create a function for that as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_geom(geom, in_epsg=None, out_epsg=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to transform shapely geometry from in_epsg to out_epsg\n",
    "    \n",
    "    Input:\n",
    "    geom: (required) : Shapely object (point/polygon/polyline)\n",
    "    in_epsg : Input EPSG for geometry; defaults to 4326\n",
    "    out_epsg: Output local EPSG for geometry; defaults to 3857\n",
    "    \n",
    "    Returns:\n",
    "    Transformed Shapely object\n",
    "    \"\"\"\n",
    "    \n",
    "    if not in_epsg:\n",
    "        in_epsg = 'epsg:3857' \n",
    "    if not out_epsg:\n",
    "        out_epsg = 'epsg:4326'\n",
    "    \n",
    "    project = partial(\n",
    "        pyproj.transform,\n",
    "        pyproj.Proj(init= in_epsg), # source coordinate system\n",
    "        pyproj.Proj(init= out_epsg)) # destination coordinate system\n",
    "\n",
    "    geom = transform(project, geom)\n",
    "    \n",
    "    return geom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This study uses multiple datasets from different sources and different resolutions. To create a cross city comparable dataset, we're aggregating / dis-aggregating data at 100m resoltuion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygonize_raster(ras_path, shp_path, string):\n",
    "    \"\"\"\n",
    "    Function to polygonize a raster based on the pixel size of base raster.\n",
    "    \n",
    "    Inputs:\n",
    "    ras_path: path to base raster location that is to be polygonized\n",
    "    shp_path: path to where the shapefile will be saved\n",
    "    string: name of the city\n",
    "    \n",
    "    Returns:\n",
    "    Geodataframe with polygons equivalent to raster pixels.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Polygonizing Raster!!\")\n",
    "    \n",
    "    import polygonize as pz\n",
    "    \n",
    "    path = os.getcwd()\n",
    "       \n",
    "    outSHPfn = path+\"\\\\shapefiles\\\\{}\".format(shp_path)\n",
    "    lat, lon = pz.main(ras_path,outSHPfn)\n",
    "\n",
    "    sh = gpd.read_file(path+\"\\\\shapefiles\\\\{}\".format(shp_path))\n",
    "    sh.crs = {'init':'epsg:4326'}\n",
    "\n",
    "    rio = rasterio.open(ras_path)\n",
    "    shp_arr = np.array(sh.geometry).reshape(rio.shape[0], rio.shape[1])\n",
    "    \n",
    "    ### The following code is creating a 2x2 point window in a 2D array to use the four points of pixel and creates a polygon\n",
    "    \n",
    "    pols = []\n",
    "    for row in range(shp_arr.shape[0]-1):\n",
    "        for col in range(shp_arr.shape[1]-1):\n",
    "            pols.append(shapely.geometry.box(shp_arr[row+1][col].x, shp_arr[row+1][col].y, shp_arr[row][col+1].x, shp_arr[row][col+1].y ))\n",
    "\n",
    "    gdf = gpd.GeoDataFrame()\n",
    "    gdf['ID'] = [i for i in range(len(pols))]\n",
    "    gdf['geometry'] = pols\n",
    "    gdf.set_geometry('geometry', inplace=True)\n",
    "    gdf.crs = {'init':'epsg:4326'}\n",
    "\n",
    "    print(\"Populating avearge height!!\")\n",
    "\n",
    "    av_h = []\n",
    "    for i in gdf.geometry:\n",
    "        coords = getFeatures(convert_geom_to_shp(i, string))\n",
    "        out_img, out_transform = mask(dataset=rio, shapes=coords, crop=True)\n",
    "        av_h.append(out_img.sum()/out_img.shape[2])\n",
    "\n",
    "    gdf['avg_height'] = av_h\n",
    "    gdf['Lon'] = [i.centroid.x for i in gdf.geometry]\n",
    "    gdf['Lat'] = [i.centroid.y for i in gdf.geometry]\n",
    "\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The output from the above function will be a Geodataframe with polygons equivalent to raster pixels. Each of those polygons will then have their location information and average height as obtained from German Space Agency data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### This next piece of code is using OSM to count the number of intersections in each of the polygons calculated above. This helps in identifying how dense the cities are and how this density changes with increase in distance from central business district (CBD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodes_from_osm(gdf, ras_path):\n",
    "    \"\"\"\n",
    "    Function to count the number of intersections in each polygon\n",
    "    \n",
    "    Input:\n",
    "    gdf : A geodataframe (Ideally a grid file for the city)\n",
    "    ras_path : raster path of base data\n",
    "    \n",
    "    Returns:\n",
    "    Geodataframe with 'node_count' column added to it.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Populating nodes from OSM!!\")\n",
    "    \n",
    "    rio = rasterio.open(ras_path)\n",
    "    pol = shapely.geometry.box(rio.bounds[0], rio.bounds[1], rio.bounds[2], rio.bounds[3])\n",
    "    \n",
    "    G = ox.graph_from_polygon(pol)\n",
    "    nodes = ox.graph_to_gdfs(G, nodes=True, edges=False)\n",
    "\n",
    "    \n",
    "    gdf.crs = {'init':'epsg:4326'}\n",
    "    gdf_copy = gdf.copy()\n",
    "    gdf_copy.to_crs(epsg=out_proj, inplace=True) \n",
    "    nodes.to_crs(epsg=out_proj, inplace=True)\n",
    "    \n",
    "    nodes['geomType'] = nodes.geom_type\n",
    "    nodes = nodes[nodes['geomType'] != 'GeometryCollection']\n",
    "    merged = gpd.sjoin( gdf_copy, nodes, how='left', op='intersects')\n",
    "    grp = merged.groupby('ID').count()\n",
    "    \n",
    "    gdf['node_count'] = grp.Lon.tolist()\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A very crucial metric we use here is the distance to CBD. This metric is important as it informs city planners about where people live and work, how the density changes with increase in this distance and what are the effects on housing market of the city. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_cbd(gdf):\n",
    "    \"\"\"\n",
    "    Function to calculate distance to CBD from each pixel center\n",
    "    \n",
    "    Input:\n",
    "    gdf: Geodataframe (ideally a grid file for the city)\n",
    "    \n",
    "    Returns:\n",
    "    Geodataframe with 'dis_to_cbd' column added to it\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Populating distance to CBD!!\")\n",
    "    \n",
    "    gdf_copy = gdf.copy()\n",
    "    gdf_copy.to_crs(epsg=out_proj, inplace=True) \n",
    "    cbd = gdf_copy[gdf_copy.node_count == gdf_copy.node_count.max()].geometry.iloc[0].centroid\n",
    "    gdf['dis_to_cbd'] = [i.centroid.distance(cbd) for i in gdf_copy.geometry]\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The function below computes the distance of each pixel from a water body. Coastal cities or cities with river banks rely on water based trade routes. This metric would help understand how it affects the density of a city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_water(gdf, gdf_water):\n",
    "    \"\"\"\n",
    "    Function to calculate distance to nearest water body\n",
    "    \n",
    "    Input:\n",
    "    gdf: Geodataframe (Ideally a grid network of the city)\n",
    "    gdf_water : Water mask geodataframe\n",
    "    \n",
    "    Returns:\n",
    "    Geodataframe with column 'dist_to_water' added to it\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Populating distance to water!!\")\n",
    "    gdf_land = gdf.copy()\n",
    "    gdf_water.to_crs(epsg=out_proj, inplace=True)\n",
    "    gdf_land.to_crs(epsg=out_proj, inplace=True)\n",
    "    \n",
    "    water_dist = []\n",
    "    \n",
    "    dest_water = MultiPoint([i.centroid for i in gdf_water.geometry])\n",
    "    \n",
    "    for i in gdf_land.index:\n",
    "        if i % 1000 == 0:\n",
    "            print(\"{0} of {1} rows processed\" .format(i, len(gdf_land)))\n",
    "\n",
    "        temp_cent = gdf_land.geometry[i].centroid\n",
    "        nearest_geoms = nearest_points(temp_cent, dest_water)\n",
    "        water_dist.append(nearest_geoms[0].distance(nearest_geoms[1]))\n",
    "    \n",
    "    gdf['dist_to_water'] = water_dist\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we'll be using high resolution Facebook population data to identify the population density of cities. Since population data has 30m resolution, we'll be aggregating the pixel values to sum the values at 100m pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iso(city):\n",
    "    \"\"\"\n",
    "    Function to get ISO-3 codes for countries\n",
    "    \n",
    "    Input:\n",
    "    city: city name (Ideally in (city, country) format)\n",
    "    \n",
    "    Returns:\n",
    "    ISO-3 code for the country\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        country = city.split(',')[1].strip().lower()\n",
    "        if country == 'south korea':  ### incorrect output for South Korea's ISO code with API\n",
    "            return 'kor'\n",
    "        else:\n",
    "            url = \"https://restcountries.eu/rest/v2/name/{}\".format(country)\n",
    "            r = requests.get(url)\n",
    "            return r.json()[0]['alpha3Code'].lower()\n",
    "    except IndexError:\n",
    "        url = \"https://restcountries.eu/rest/v2/capital/{}\".format(city)\n",
    "        r = requests.get(url)\n",
    "        return r.json()[0]['alpha3Code'].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(gdf):\n",
    "    \"\"\"Function to parse features from GeoDataFrame in such a manner that rasterio accepts them\"\"\"\n",
    "    import json\n",
    "    return [json.loads(gdf.to_json())['features'][0]['geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_population(gdf, city, ras_path):\n",
    "    \"\"\"\n",
    "    Function to estimate population for each pixel\n",
    "    \n",
    "    gdf: Geodataframe (Ideally a grid network of the city)\n",
    "    city: city name (Ideally in (city, country) format)\n",
    "    ras_path: path to population raster\n",
    "    \n",
    "    Returns:\n",
    "    Geodataframe with aggregated population in 'population' column\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Populating population from Facebook!!\")\n",
    "    \n",
    "    iso = get_iso(city)\n",
    "    \n",
    "    fbras_lis = glob.glob(os.getcwd()+\"\\\\*{}*tif\".format(iso))\n",
    "    \n",
    "    rio = rasterio.open(ras_path)\n",
    "    \n",
    "    pol = shapely.geometry.box(rio.bounds[0], rio.bounds[1], rio.bounds[2], rio.bounds[3])\n",
    "    \n",
    "    ## Parsing through multiple rasters to check which one intersects with input data\n",
    "    \n",
    "    if len(fbras_lis)>1:\n",
    "        for path_ in fbras_lis:\n",
    "            ras = rasterio.open(path_)\n",
    "            if pol.intersects(shapely.geometry.box(ras.bounds[0], ras.bounds[1], ras.bounds[2], ras.bounds[3])):\n",
    "                pop_path = path_\n",
    "    else:\n",
    "        pop_path = fbras_lis[0]\n",
    "        \n",
    "        \n",
    "    pop = rasterio.open(pop_path)\n",
    "    \n",
    "    fb_pop = []\n",
    "    \n",
    "    for i in gdf.index:\n",
    "        _gdf = gdf[gdf.index == i]\n",
    "\n",
    "        _coords = getFeatures(_gdf)\n",
    "\n",
    "        _out_img, _out_transform = mask(dataset=pop, shapes=_coords, crop=True)\n",
    "\n",
    "        outimg = np.nan_to_num(_out_img)\n",
    "        outimg = outimg.reshape(outimg.shape[1], outimg.shape[2])\n",
    "\n",
    "        fb_pop.append(outimg.sum())\n",
    "        \n",
    "    gdf['population'] = fb_pop\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subways are increasingly becoming relaible mode of transportation in cities. With this analysis we wanted to know the distance to nearest subway stop from each of the pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subway_data(city):\n",
    "    \"\"\"\n",
    "    Function seacrches for subway data for cities on either local files or queries data from OSM.\n",
    "    \n",
    "    city: city name (Ideally in (city, country) format)\n",
    "    \n",
    "    Returns:\n",
    "    Geodataframe with subway stations as point features or None if OSM query contains no data\n",
    "    \"\"\"\n",
    "    \n",
    "    string = city.split(\",\")[0]\n",
    "    \n",
    "    str_ = string.replace(' ','')\n",
    "     \n",
    "    sub_path = os.getcwd()+\"\\Subway and growth\\subway_census_v1\\station_points\"\n",
    "    \n",
    "    sub_data = gpd.read_file(sub_path+\"\\\\subway_stations2.shp\")\n",
    "    \n",
    "    if str_ in sub_data.CITY1.unique():\n",
    "        city_data = sub_data[sub_data.CITY1 == str_]\n",
    "        return pois\n",
    "    else:\n",
    "        bbox = geocoder.arcgis(city).geojson['features'][0]['bbox']\n",
    "        amenities = ['subway', 'light_rail', 'metro', 'underground', 'monorail', 'tram']\n",
    "        osm_tags = '\"railway\"~\"{}\"'.format('|'.join(amenities))\n",
    "        try:\n",
    "            pois = osm.node_query(bbox[1], bbox[0], bbox[3], bbox[2],tags=osm_tags) ##lat_min, lng_min, lat_max, lng_max\n",
    "            return pois\n",
    "    \n",
    "        except RuntimeError as e:\n",
    "            if e.args[0] == \"OSM query results contain no data.\":\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_subway(gdf, city):\n",
    "    \"\"\"\n",
    "    Function computes distance to nearest metro station for each pixel\n",
    "    \n",
    "    gdf: Geodataframe (Ideally a grid network of the city)\n",
    "    city : city name (Ideally in (city, country) format)\n",
    "    \n",
    "    Returns:\n",
    "    Geodataframe with 'dis_to_subway' column added to it\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Populating distance to Subway stations!!\")\n",
    "     \n",
    "    if not gdf.crs:\n",
    "        gdf.crs = {'init':'epsg:4326'}\n",
    "        \n",
    "    gdf_copy = gdf.copy()\n",
    "    \n",
    "    gdf_copy.to_crs(epsg=out_proj, inplace=True)\n",
    "    \n",
    "    data =  get_subway_data(city)       \n",
    "    \n",
    "    if data:\n",
    "        metro_dist = []\n",
    "\n",
    "        dest = MultiPoint([i for i in data.geometry])\n",
    "\n",
    "        for i in gdf_copy.index:\n",
    "            if i % 1000 == 0:\n",
    "                print(\"{0} of {1} rows processed\" .format(i, len(gdf_copy)))\n",
    "\n",
    "            temp_cent = gdf_copy.geometry.iloc[i].centroid\n",
    "\n",
    "            nearest_geoms = nearest_points(temp_cent, dest)\n",
    "            metro_dist.append(nearest_geoms[0].distance(nearest_geoms[1]))\n",
    "    else:\n",
    "        metro_dist = [0 for i in range(len(gdf_copy))]\n",
    "        \n",
    "    gdf['dis_to_subway'] = metro_dist\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we compute distance to nearest highway entry/exit point. Highway data is queried from OSM API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_hwy(gdf, city):\n",
    "    \n",
    "    print(\"Populating distance to highways!!\")\n",
    "        \n",
    "    if not gdf.crs:\n",
    "        gdf.crs = {'init':'epsg:4326'}\n",
    "    \n",
    "    gdf_copy = gdf.copy()\n",
    "    \n",
    "    gdf_copy.to_crs(epsg=out_proj, inplace=True)\n",
    "    \n",
    "    bbox = geocoder.arcgis(\"{}\".format(city)).geojson['features'][0]['properties']['raw']['extent']\n",
    "    \n",
    "    highway = ['motorway', 'trunk', 'primary', 'secondary', 'tertiary', 'residential']\n",
    "    osm_tags = '\"highway\"~\"{}\"'.format('|'.join(highway))\n",
    "    try:\n",
    "        highway_pois = osm.node_query(bbox['ymin'],bbox['xmin'],bbox['ymax'],bbox['xmax'],tags=osm_tags) ##lat_min, lng_min, lat_max, lng_max\n",
    "\n",
    "        highway_pois = highway_pois[['lat', 'lon', 'highway', 'name']]\n",
    "        ## Adding geometry to the dataset\n",
    "        highway_pois['geometry'] = (list(zip(highway_pois.lon,highway_pois.lat)))\n",
    "        highway_pois['geometry'] = highway_pois.geometry.apply(lambda x: Point(x))\n",
    "        highway_pois = gpd.GeoDataFrame(highway_pois, geometry='geometry')\n",
    "        highway_pois.crs = {'init':'epsg:4326'}\n",
    "\n",
    "        highway_pois.to_crs(epsg=out_proj, inplace=True)\n",
    "\n",
    "        hwy_dist = []\n",
    "\n",
    "        dest_hwy = MultiPoint([i for i in highway_pois.geometry])\n",
    "\n",
    "        for i in gdf_copy.index:\n",
    "            if i % 1000 == 0:\n",
    "                print(\"{0} of {1} rows processed\" .format(i, len(gdf_copy)))\n",
    "\n",
    "            temp_cent = gdf_copy.geometry.iloc[i].centroid\n",
    "\n",
    "            nearest_geoms = nearest_points(temp_cent, dest_hwy)\n",
    "            hwy_dist.append(nearest_geoms[0].distance(nearest_geoms[1]))\n",
    "    except RuntimeError as e:\n",
    "            if e.args[0] == \"OSM query results contain no data.\":\n",
    "                 hwy_dist = [0 for i in range(len(gdf))]\n",
    "            else:\n",
    "                print(e)\n",
    "    \n",
    "    gdf['dis_to_hwy'] = hwy_dist\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The last metric we'll use is identifying the year each of the pixels was built using DLR Evolution data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_built_year(gdf, string):\n",
    "    \"\"\"\n",
    "    Function to identify minimum and maximum of year for each of the pixels\n",
    "    \n",
    "    Input:\n",
    "    gdf: Geodataframe (Ideally a grid network of the city)\n",
    "    string : city name \n",
    "    \n",
    "    Returns:\n",
    "    Geodataframe with 'Yr_min_built' and 'Yr_max_built' columns added to it\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Populating builup year!!\")\n",
    "    \n",
    "    ras_path = glob.glob(os.getcwd()+\"\\Data\\DLR Data\\\\*{}*_WSFevolution.tif\".format(string))[0]\n",
    "    \n",
    "    ras = rasterio.open(ras_path)\n",
    "    \n",
    "    min_, max_ = [], []\n",
    "    for i in gdf.index:\n",
    "        if i % 1000 == 0:\n",
    "            print(\"{0} of {1} rows processed\" .format(i, len(gdf)))\n",
    "\n",
    "        gdf_ = convert_geom_to_shp(gdf.geometry[i], 'Auckland')\n",
    "        coords = getFeatures(gdf_)\n",
    "        out_img, out_transform = mask(dataset=ras, shapes=coords, crop=True)\n",
    "        un = np.unique(out_img)\n",
    "        if (un[0] == 0) and (len(un) > 1):\n",
    "            min_.append(un[1])\n",
    "        else:\n",
    "            min_.append(un[0])\n",
    "\n",
    "        max_.append(un[-1])\n",
    "            \n",
    "    gdf['Yr_min_built'] = min_\n",
    "    gdf['Yr_max_built'] = max_\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the main function to call other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(t1, t2):\n",
    "    \"\"\"\n",
    "    Function to return difference between two timestamps\n",
    "    \n",
    "    t1: initial time\n",
    "    t2: final time\n",
    "    \"\"\"\n",
    "    diff = t2 - t1\n",
    "    \n",
    "    c = round(diff.total_seconds() / 60, 2)\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(city):\n",
    "    \"\"\"\n",
    "    Main function to compute all the metrics required for analysis of city growth\n",
    "    \n",
    "    Input:\n",
    "    city: city name (Ideally in (city, country) format)\n",
    "    \n",
    "    Returns:\n",
    "    None; Writes a shapefile at \"pixel_level_files\" location\n",
    "    \"\"\"\n",
    "    \n",
    "    import datetime\n",
    "    global out_proj\n",
    "    \n",
    "    string = city.split(',')[0]\n",
    "    path = os.getcwd()\n",
    "    \n",
    "    ras_path = glob.glob(os.getcwd()+\"\\Data\\DLR Data\\\\*{}*WSF3D_AW3D30.tif\".format(string))[0]\n",
    "    shp_path = \"{}_grid.shp\".format(string)\n",
    "    \n",
    "    out_proj = get_city_proj_crs(city)\n",
    "    \n",
    "    t1 = datetime.datetime.now()\n",
    "    \n",
    "    gdf = polygonize_raster(ras_path, shp_path, string)\n",
    "\n",
    "    gdf_water = gdf[gdf.avg_height == 0.0]\n",
    "    gdf_water.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    gdf_land = gdf[gdf.avg_height != 0.0]\n",
    "    gdf_land.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    gdf_water.crs = {'init':'epsg:4326'}\n",
    "    \n",
    "    gdf_land.crs = {'init':'epsg:4326'}\n",
    "    \n",
    "    gdf_land = nodes_from_osm(gdf_land, ras_path)\n",
    "\n",
    "    gdf_land = get_distance_cbd(gdf_land)\n",
    "\n",
    "    gdf_land = get_distance_water(gdf_land, gdf_water)\n",
    "\n",
    "    gdf_land = get_population(gdf_land, city, ras_path)\n",
    "    \n",
    "    gdf_land = get_distance_subway(gdf_land, city)\n",
    "    \n",
    "    gdf_land = get_distance_hwy(gdf_land, city)\n",
    "    \n",
    "    gdf_land = get_built_year(gdf_land, string)\n",
    "    \n",
    "    print(\"Writing data to shapefile!!\")\n",
    "    \n",
    "    gdf_land.to_file(path+\"\\\\pixel_level_files\\\\{}_pixel_level_data.shp\".format(string))\n",
    "    \n",
    "    t2 = datetime.datetime.now()\n",
    "    \n",
    "    print('Total time taken to run the analysis: {}'.format(get_time(t1, t2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "main('Auckland, New Zealand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
